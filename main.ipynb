{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into DataFrames\n",
    "\n",
    "# Emissions data\n",
    "nrg_emi_df = pd.read_excel(io=\"data/Statistical Review of World Energy Data.xlsx\", sheet_name=\"CO2 Emissions from Energy\", header=2, index_col=0)\n",
    "# The sheet called \"Natural Gas Flaring\" is already a part of the calculations for the sheet called \"CO2 from Flaring\"\n",
    "flar_emi_df = pd.read_excel(io=\"data/Statistical Review of World Energy Data.xlsx\", sheet_name=\"CO2 from Flaring\", header=2, index_col=0)\n",
    "equi_emi_df = pd.read_excel(io=\"data/Statistical Review of World Energy Data.xlsx\", sheet_name=\"CO2e Methane, Process emissions\", header=2, index_col=0)\n",
    "\n",
    "# Renewable energy data\n",
    "hydro_df = pd.read_excel(io=\"data/Statistical Review of World Energy Data.xlsx\", sheet_name=\"Hydro Generation - TWh\", header=2, index_col=0)\n",
    "solar_df = pd.read_excel(io=\"data/Statistical Review of World Energy Data.xlsx\", sheet_name=\"Solar Generation - TWh\", header=2, index_col=0)\n",
    "wind_df = pd.read_excel(io=\"data/Statistical Review of World Energy Data.xlsx\", sheet_name=\"Wind Generation - TWh\", header=2, index_col=0)\n",
    "geo_df = pd.read_excel(io=\"data/Statistical Review of World Energy Data.xlsx\", sheet_name=\"Geo Biomass Other - TWh\", header=2, index_col=0)\n",
    "biofuel_df = pd.read_excel(io=\"data/Statistical Review of World Energy Data.xlsx\", sheet_name=\"Biofuels production - PJ\", header=2, index_col=0, nrows=47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmatic data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(df:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Get an excel sheet ready for conversion to numpy arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): a dataframe containing an excel sheet\n",
    "    \"\"\"\n",
    "    #------------------------------ \n",
    "    # Remove all irrelevant columns\n",
    "    #------------------------------\n",
    "\n",
    "    # Remove all data from before 1990\n",
    "    # Find the index of the \"1990\" column\n",
    "    drop_indx = list(df.columns).index(1990)\n",
    "    # Get the column labels of all columns left of \"1990\"\n",
    "    drop_cols = [df.columns[num] for num in np.arange(0, drop_indx)]\n",
    "    df = df.drop(columns=drop_cols)\n",
    "\n",
    "    # Remove data on growth-rate and share\n",
    "    # Get the column labels of the target columns\n",
    "    drop_cols = [df.columns[num] for num in [-3, -2, -1]]\n",
    "    df = df.drop(columns=drop_cols)\n",
    "\n",
    "    #---------------------------\n",
    "    # Remove all irrelevant rows\n",
    "    #---------------------------\n",
    "\n",
    "    # Remove all rows with any empty cells\n",
    "    # 0 doesn't make an empty cell\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Remove all \"Total\" and \"Other\" rows\n",
    "    # In addition, OECD, Non-OECD, the EU, and the USSR\n",
    "    # Rationale for removing \"Other\" rows - some countries in some excel sheets appear\n",
    "    # individually, but are lumped into an \"Other\" row in other sheets.\n",
    "    # There's no possible way for me to know which portions of an\n",
    "    # \"Other\" row value belongs to which countries.\n",
    "    drop_rows = []\n",
    "    keywords = [\"Total\", \"Other\", \"OECD\", \"European Union\", \"USSR\"]\n",
    "    for row in df.index:\n",
    "        # Mark a row for dropping if it contains any of the keywords\n",
    "        if any(keyword in row for keyword in keywords):\n",
    "            drop_rows.append(row)\n",
    "    df = df.drop(index=drop_rows)\n",
    "\n",
    "    # -----------------\n",
    "    # Convert the units\n",
    "    # -----------------\n",
    "\n",
    "    # All CO2 data is currently represented as millions of tonnes\n",
    "    # Convert all renewable data to kilowatt-hour (kWh)\n",
    "    # 1 kWh = 3600 kJ\n",
    "    # 1 PJ = 1000000000000 kJ\n",
    "    # 1 TWh = 1000000000 kWh\n",
    "\n",
    "    if (df.index.name) == \"Million tonnes of carbon dioxide\":\n",
    "        df = df * 1000000\n",
    "    elif df.index.name == \"Terawatt-hours\":\n",
    "        df = df * 1000000000\n",
    "    elif df.index.name == \"Petajoules\":\n",
    "        df = df * (1000000000000/3600)\n",
    "\n",
    "    return df\n",
    "\n",
    "# tonnes = metric ton = 1000 kg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowIndices(df:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Return the row labels of a pd.DataFrame\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): a dataframe containing an excel sheet\n",
    "    \"\"\"\n",
    "\n",
    "    return [row for row in df.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process dataframes\n",
    "\n",
    "nrg_emi_df = processData(nrg_emi_df)\n",
    "flar_emi_df = processData(flar_emi_df)\n",
    "equi_emi_df = processData(equi_emi_df)\n",
    "\n",
    "hydro_df = processData(hydro_df)\n",
    "solar_df = processData(solar_df)\n",
    "wind_df = processData(wind_df)\n",
    "geo_df = processData(geo_df)\n",
    "biofuel_df = processData(biofuel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "\n",
    "nrg_emi = nrg_emi_df.to_numpy()\n",
    "flar_emi = flar_emi_df.to_numpy()\n",
    "equi_emi = equi_emi_df.to_numpy()\n",
    "hydro = hydro_df.to_numpy()\n",
    "solar = solar_df.to_numpy()\n",
    "wind = wind_df.to_numpy()\n",
    "geo = geo_df.to_numpy()\n",
    "biofuel = biofuel_df.to_numpy()\n",
    "\n",
    "# Get row indices of dataframes\n",
    "# Only these dataframes were selected because they cover different lists of locations. \n",
    "# This leads to different lists of indices.\n",
    "# len(nrg_emi_indices) = 83\n",
    "# len(flar_emi_indices) = 49\n",
    "# len(biofuel_indices) = 24\n",
    "# The rest of the dataframes share the same index list as nrg_emi_indices\n",
    "nrg_emi_indices = rowIndices(nrg_emi_df)\n",
    "flar_emi_indices = rowIndices(flar_emi_df)\n",
    "biofuel_indices = rowIndices(biofuel_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>nrg_emi_indices:</b>\n",
    "\n",
    "['Canada', 'Mexico', 'US', 'Argentina', 'Brazil', 'Chile', 'Colombia', 'Ecuador', 'Peru', 'Trinidad & Tobago', 'Venezuela', 'Central America', 'Austria', 'Belgium', 'Bulgaria', 'Croatia', 'Cyprus', 'Czech Republic', 'Denmark', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Latvia', 'Lithuania', 'Luxembourg', 'Netherlands', 'North Macedonia', 'Norway', 'Poland', 'Portugal', 'Romania', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'Turkey', 'Ukraine', 'United Kingdom', 'Azerbaijan', 'Belarus', 'Kazakhstan', 'Russian Federation', 'Turkmenistan', 'Uzbekistan', 'Iran', 'Iraq', 'Israel', 'Kuwait', 'Oman', 'Qatar', 'Saudi Arabia', 'United Arab Emirates', 'Algeria', 'Egypt', 'Morocco', 'South Africa', 'Eastern Africa', 'Middle Africa', 'Western Africa', 'Australia', 'Bangladesh', 'China', 'China Hong Kong SAR', 'India', 'Indonesia', 'Japan', 'Malaysia', 'New Zealand', 'Pakistan', 'Philippines', 'Singapore', 'South Korea', 'Sri Lanka', 'Taiwan', 'Thailand', 'Vietnam']\n",
    "\n",
    "<b>flar_emi_indices:</b>\n",
    "\n",
    "['Canada', 'Mexico', 'US', 'Argentina', 'Bolivia', 'Brazil', 'Colombia', 'Peru', 'Trinidad & Tobago', 'Venezuela', 'Denmark', 'Germany', 'Italy', 'Netherlands', 'Norway', 'Poland', 'Romania', 'Ukraine', 'United Kingdom', 'Azerbaijan', 'Kazakhstan', 'Russian Federation', 'Turkmenistan', 'Uzbekistan', 'Bahrain', 'Iran', 'Iraq', 'Kuwait', 'Oman', 'Qatar', 'Saudi Arabia', 'Syria', 'United Arab Emirates', 'Yemen', 'Algeria', 'Egypt', 'Libya', 'Nigeria', 'Australia', 'Bangladesh', 'Brunei', 'China', 'India', 'Indonesia', 'Malaysia', 'Myanmar', 'Pakistan', 'Thailand', 'Vietnam']\n",
    "\n",
    "<b>biofuel_indices:</b>\n",
    "\n",
    "['Canada', 'Mexico', 'US', 'Argentina', 'Brazil', 'Colombia', 'Austria', 'Belgium', 'Finland', 'France', 'Germany', 'Italy', 'Netherlands', 'Poland', 'Portugal', 'Spain', 'Sweden', 'United Kingdom', 'Australia', 'China', 'India', 'Indonesia', 'South Korea', 'Thailand']\n",
    "\n",
    "<b>Shape of nrg_emi_df and nrg_emi:</b>\n",
    "\n",
    "(83, 33)\n",
    "\n",
    "<b>Columns of every dataframe:</b>\n",
    "\n",
    "Index([1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001,\n",
    "       2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013,\n",
    "       2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022],\n",
    "      dtype='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Algeria', 'Argentina', 'Australia', 'Austria', 'Azerbaijan', 'Bahrain', 'Bangladesh', 'Belarus', 'Belgium', 'Bolivia', 'Brazil', 'Brunei', 'Bulgaria', 'Canada', 'Central America', 'Chile', 'China', 'China Hong Kong SAR', 'Colombia', 'Croatia', 'Cyprus', 'Czech Republic', 'Denmark', 'Eastern Africa', 'Ecuador', 'Egypt', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran', 'Iraq', 'Ireland', 'Israel', 'Italy', 'Japan', 'Kazakhstan', 'Kuwait', 'Latvia', 'Libya', 'Lithuania', 'Luxembourg', 'Malaysia', 'Mexico', 'Middle Africa', 'Morocco', 'Myanmar', 'Netherlands', 'New Zealand', 'Nigeria', 'North Macedonia', 'Norway', 'Oman', 'Pakistan', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Qatar', 'Romania', 'Russian Federation', 'Saudi Arabia', 'Singapore', 'Slovakia', 'Slovenia', 'South Africa', 'South Korea', 'Spain', 'Sri Lanka', 'Sweden', 'Switzerland', 'Syria', 'Taiwan', 'Thailand', 'Trinidad & Tobago', 'Turkey', 'Turkmenistan', 'US', 'Ukraine', 'United Arab Emirates', 'United Kingdom', 'Uzbekistan', 'Venezuela', 'Vietnam', 'Western Africa', 'Yemen']\n",
      "(33, 91, 8)\n"
     ]
    }
   ],
   "source": [
    "# Combine it all into one massive 3D numpy array\n",
    "# 1st dimension - Years. 33 years from 1990-2022 (inclusive)\n",
    "# 2nd dimension - Countries/Regions. 91 unique countrie/regions\n",
    "# 3rd dimension - Carbon Neutral features. 8 features (in this order): energy emissions, flaring emissions, CO2 equivalent emissions, \n",
    "# hydroelectric production, solar production, wind production, geothermal production, biofuel production\n",
    "# (33, 91, 8)\n",
    "\n",
    "# Find every unique country/region\n",
    "cotry_reg = list(set(nrg_emi_indices + flar_emi_indices + biofuel_indices))\n",
    "cotry_reg.sort()\n",
    "print(cotry_reg)\n",
    "\n",
    "dim_1 = []\n",
    "for year_indx in range(33):\n",
    "    dim_2 = []\n",
    "    for area in cotry_reg:\n",
    "        if area in nrg_emi_indices:\n",
    "            indx = nrg_emi_indices.index(area)\n",
    "            # Extract a float\n",
    "            a_nrg_emi = nrg_emi[indx][year_indx]\n",
    "            a_equi_emi = equi_emi[indx][year_indx]\n",
    "            a_hydro = hydro[indx][year_indx]\n",
    "            a_solar = solar[indx][year_indx]\n",
    "            a_wind = wind[indx][year_indx]\n",
    "            a_geo = geo[indx][year_indx]\n",
    "        else:\n",
    "            a_nrg_emi = a_equi_emi = a_hydro = a_solar = a_wind = a_geo = 0.\n",
    "\n",
    "        if area in flar_emi_indices:\n",
    "            indx = flar_emi_indices.index(area)\n",
    "            # Extract a float\n",
    "            a_flar_emi = flar_emi[indx][year_indx]\n",
    "        else:\n",
    "            a_flar_emi = 0.\n",
    "\n",
    "        if area in biofuel_indices:\n",
    "            indx = biofuel_indices.index(area)\n",
    "            # Extract a float\n",
    "            a_biofuel = biofuel[indx][year_indx]\n",
    "        else:\n",
    "            a_biofuel = 0.\n",
    "\n",
    "        # Is also a set of features\n",
    "        dim_3 = [a_nrg_emi,\n",
    "                a_flar_emi,\n",
    "                a_equi_emi,\n",
    "                a_hydro,\n",
    "                a_solar,\n",
    "                a_wind,\n",
    "                a_geo,\n",
    "                a_biofuel]\n",
    "        dim_2.append(dim_3)\n",
    "    dim_1.append(dim_2)\n",
    "\n",
    "print(np.shape(dim_1))\n",
    "# Statistical Review \n",
    "sr = np.array(dim_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLabel(features):\n",
    "    \"\"\"\n",
    "    Make a label for a sample\n",
    "\n",
    "    - features (np.ndarray): set of 8 features\n",
    "    \"\"\"\n",
    "    # Unit: Tonnes of Carbon Dioxide\n",
    "    co2 = np.sum(features[:3])\n",
    "    # Unit: Kilowatt-hours\n",
    "    renewable = np.sum(features[3:])\n",
    "\n",
    "    # Electricity reductions emission factor\n",
    "    # 0.000709 tonnes CO2/kWh\n",
    "    # Unit: Tonnes of Carbon Dioxide\n",
    "    renewable *= 0.000709\n",
    "\n",
    "    # Remaining co2 after being offset by renewable energy production\n",
    "    rem_co2 = max(co2 - renewable, 0)\n",
    "\n",
    "    if rem_co2 == co2:\n",
    "        return 10\n",
    "    else:\n",
    "        percent = (rem_co2/co2) * 100\n",
    "        # Equivalent to np.floor(percent / 10)\n",
    "        # The label is the tens place of the percentage\n",
    "        return int(np.floor(percent / 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 91)\n"
     ]
    }
   ],
   "source": [
    "# Make labels for all of the data/samples/examples \n",
    "# An individual feature isn't a example, but a location in a particular year is\n",
    "# Thus, there are 33 * 91 = 3003 examples\n",
    "\n",
    "# There are 11 possible labels, 0-10\n",
    "# 0 means carbon neutral is achieved\n",
    "# 10 means the country is absolutely nowhere near carbon neutrality\n",
    "labels = np.array([[makeLabel(location) for location in year] for year in sr])\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1st Training phase: Train a classifier on the first two labeled years of the data\n",
    "- 2nd Training phase: Use the classifier and batch active learning on the rest of the unlabeled data until 2021. Examples that would provide the most information will be chosen to get their true label. The remaining examples will get pseudo-labeled\n",
    "- Evaluate phase: Use the now trained classifier to evaluate the data from 2021 and 2022\n",
    "- Predict phase: Use time series forecasting (RNN) to predict a country's set of features until 2050. Use the classifier to predict levels of CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eclid_dist(vector1, vector2):\n",
    "    return np.linalg.norm(vector1 - vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfinished\n",
    "def accuracy_fn(pred_labels: np.ndarray, true_labels: np.ndarray):\n",
    "    try:\n",
    "        if pred_labels.shape != true_labels.shape:\n",
    "            raise IndexError\n",
    "        # Assuming the arguments are 2-dimensional\n",
    "        \n",
    "\n",
    "    except IndexError:\n",
    "        print(\"There are unequal amount of labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 91, 8)\n",
      "(2, 91)\n",
      "(29, 91, 8)\n",
      "(29, 91)\n",
      "(2, 91, 8)\n",
      "(2, 91)\n"
     ]
    }
   ],
   "source": [
    "# Years 1990-1991\n",
    "lab_set = sr[0:2]\n",
    "lab_set_label = labels[0:2]\n",
    "# Years 1992-2020\n",
    "unlab_set = sr[2:31]\n",
    "unlab_set_label = labels[2:31]\n",
    "# Years 2021-2022\n",
    "test_set = sr[31::]\n",
    "test_set_label = labels[31::]\n",
    "\n",
    "print(lab_set.shape)\n",
    "print(lab_set_label.shape)\n",
    "print(unlab_set.shape)\n",
    "print(unlab_set_label.shape)\n",
    "print(test_set.shape)\n",
    "print(test_set_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,)]\n",
      "[(8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,), (8,)]\n"
     ]
    }
   ],
   "source": [
    "for areas, label in zip(lab_set, lab_set_label):\n",
    "    # print(areas.shape, label.shape)\n",
    "    print([area.shape for i, area in enumerate(areas)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Active Learning\n",
    "def batch_active_learning(classifier, lab_data, lab_label, unlab_data, unlab_label):\n",
    "    \"\"\"Train a classifier using batch active learning\n",
    "    \n",
    "    Parameters:\n",
    "    - classifier: a classifier from the scikit-learn (sklearn) module \n",
    "    - lab_data (ndarray): the labeled dataset, shape=(2, 91, 8)\n",
    "    - lab_label (ndarray): the labled dataset's labels, shape=(2, 91)\n",
    "    - unlab_data (ndarray): the unlabeled dataset, shape=(29, 91, 8)\n",
    "    - unlab_label (ndarray): the unlabeled dataset's labels, shape=(29, 91)\n",
    "    \"\"\"\n",
    "\n",
    "    # loop runs 2 times\n",
    "    for areas, label in zip(lab_data, lab_label):\n",
    "        # location.shape = (91, 8)\n",
    "        # label.shape = (91,)\n",
    "        classifier.fit(areas, label)\n",
    "\n",
    "    # loop runs 29 times\n",
    "    for areas, label in zip(unlab_data, unlab_label):\n",
    "        # location.shape = (91, 8)\n",
    "        # label.shape = (91,)\n",
    "        # area.shape = (8,), the set of features\n",
    "        request = [area for area in areas]\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Naive Bayes isn't an option becasue sample features must be binary-valued (Bernoulli, boolean)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "\n",
    "classifier = batch_active_learning(classifier, lab_set, lab_set_label, unlab_set, unlab_set_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 5, 6, 7, 8, 9, 10}\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n"
     ]
    }
   ],
   "source": [
    "print(set(labels[0]))\n",
    "print(set(labels[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN classifier class\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features=8, out_features=16)\n",
    "        # nn.ReLU() doesn't need parameters in this case\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features=16, out_features=16)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(in_features=16, out_features=16)\n",
    "        self.activation3 = nn.ReLU()\n",
    "        # self.batchNorm = nn.BatchNorm1d()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        # self.dropout1 = nn.Dropout()\n",
    "        self.dense1 = nn.Linear(in_features=16, out_features=1)\n",
    "        # self.dropout2 = nn.Dropout()\n",
    "        # self.dense2 = nn.Linear()\n",
    "        # self.dropout3 = nn.Dropout()\n",
    "        # self.dense3 = nn.Linear()\n",
    "        # self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.activation3(x)\n",
    "        # x = self.batchNorm(x)\n",
    "        # x = self.flatten(x)\n",
    "        # x = self.dropout1(x)\n",
    "        x = self.dense1(x)\n",
    "        # x = self.dropout2(x)\n",
    "        # x = self.dense2(x)\n",
    "        # x = self.dropout3(x)\n",
    "        # x = self.dense3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RNN_classifier = CustomModel().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(RNN_classifier.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series forecasting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
